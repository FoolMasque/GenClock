





import math
import os
import torch
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont
import random





def preprocess_image(image, augment=False, augment_prob=0.8):

    def add_noise(tensor):
        # Adding Noise to a Tensor
        noise = torch.randn(tensor.size()) * 0.01
        tensor = tensor + noise
        return tensor

    # Creating an Image Conversion List
    transform_list = [transforms.Resize((64, 64), antialias=True),  # Resize
                      transforms.ToTensor(),   # Converting images to PyTorch tensors
                      transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                           std=[0.229, 0.224, 0.225])]

    augment_transforms = [transforms.ColorJitter(),  # Randomly adjusts the brightness, contrast and saturation of the image.
                          transforms.RandomErasing(scale=(0.01, 0.01)), # Erases a random area in the image.
                          transforms.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.7, 1.2))]  # Perform random affine transformations on images, including rotation, translation and scaling.

    # If data enhancement is performed, some enhanced transformations are randomly selected and added to the transformation list
    if augment and random.random() < augment_prob:
        selected_augment_transforms = random.sample(augment_transforms, k=random.randint(1, len(augment_transforms)))
        transform_list.extend(selected_augment_transforms)
        # Adding Noise with Lambda Transformations
        transform_list.append(transforms.Lambda(add_noise))
    # Combined conversion
    composed_transforms = transforms.Compose(transform_list)

    # Application Conversion
    augmented_tensor = composed_transforms(image)

    return augmented_tensor








# Creating a dataloader

class ClockDataset(Dataset):
    def __init__(self, data_dir, augment=True):
        self.data_dir = data_dir
        self.images = [filename for filename in os.listdir(data_dir) if filename.endswith('.png')]
        self.augment = augment

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.data_dir, self.images[idx])
        image = Image.open(img_path)
        normalized_tensor = preprocess_image(image, augment=self.augment)
        label_path = img_path.replace('.png', '.txt')
        with open(label_path, 'r') as f:
            label = f.read().strip().split(':')
            hour, minute = float(label[0]), float(label[1])
            # Coding hours and minutes using cyclic coding
            encoded_hour = [math.sin(2 * math.pi * hour / 12), math.cos(2 * math.pi * hour / 12)]
            encoded_minute = [math.sin(2 * math.pi * minute / 60), math.cos(2 * math.pi * minute / 60)]

        return normalized_tensor, torch.tensor(encoded_hour + encoded_minute, dtype=torch.float32)











# Define ChannelAttention
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        # Average pooling
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        # Max Pooling
        self.max_pool = nn.AdaptiveMaxPool2d(1)

        # MLP  Dividing by 16 is the coefficient of descent.
        self.fc1 = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)  # kernel_size=1
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)

        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))
        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))
        # The results add up
        out = avg_out + max_out
        return self.sigmoid(out)

# Define Space Attention
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()
        # Assert the convolution kernel as 3 or 7
        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'
        # Make the appropriate same padding padding
        padding = 3 if kernel_size == 7 else 1

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)  # Average pooling
        max_out, _ = torch.max(x, dim=1, keepdim=True)  # Max Pooling
        # Concate operation
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)  # 7x7 conv padding of 3, input channel 2, output channel 1
        return self.sigmoid(x)
# Combine
class CBAM(nn.Module):
    def __init__(self, in_channels):
        super(CBAM, self).__init__()
        self.channel_att = ChannelAttention(in_channels)
        self.spatial_att = SpatialAttention()

    def forward(self, x):
        att = 1 + self.channel_att(x) * x
        att = att + self.spatial_att(att)
        return att





# Design the network architecture

class CartoonClockCNN(nn.Module):
    def __init__(self):
        super(CartoonClockCNN, self).__init__()
        # Defining Convolutional Layers
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)

        # Attention
        self.attention = CBAM(32)
        self.attention2 = CBAM(128)

        # Defining fully connected layers
        self.fc1 = nn.Linear(256 * 4 * 4, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 4) # 4 outputs for hour and minute encoding

        # Defining fully connected layers
        self.dropout = nn.Dropout(0.2)

        # Initialize Network Weights
        self._initialize_weights()

        # Defining BN layers
        self.bn1 = nn.BatchNorm2d(64)
        self.bn2 = nn.BatchNorm2d(128)
        self.bn3 = nn.BatchNorm2d(256)

    def forward(self, x):

        x = F.relu(self.dropout(self.conv1(x)))  # 3*64x64 -> 32*64x64
        x = F.max_pool2d(x, 2, 2)  # 32*64x64 -> 32*32x32
        x = self.conv2(x)  # 32*32x32 -> 64*32x32
        x = F.leaky_relu(self.bn1(x))
        x = F.max_pool2d(x, 2, 2)  # 64*32x32 -> 64*16x16
        x = F.relu(self.bn2(self.dropout(self.conv3(x))))  # 64*16x16-> 128*16x16
        x = F.max_pool2d(x, 2, 2)  # 128*16x16 -> 128*8x8
        x = F.leaky_relu(self.bn3(self.conv4(x)))  # 128*8x8 -> 256*8x8
        x = F.max_pool2d(x, 2, 2)  # 256*8x8 -> 256*4x4

        x = x.view(x.size(0), -1)  # 256*4*4 -> 4096 Adjusting fully connected layer inputs to convolutional layer outputs
        x = self.fc1(x) # 256
        x = F.tanh(x)
        x = F.relu(self.dropout(self.fc2(x))) # 128
        x = self.fc3(x) # 4

        return x

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
                nn.init.constant_(m.bias, 0)








def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # Creating a Network Instance
    model = CartoonClockCNN().to(device)
    train_dataset = ClockDataset('datasets/clocks_dataset/train')
    # train_dataset = ClockDataset('datasets/sub_clock')

    # Splite Dataset
    train_indices, val_indices = train_test_split(list(range(len(train_dataset))), test_size=0.2)
    train_subset = torch.utils.data.Subset(train_dataset, train_indices)
    val_subset = torch.utils.data.Subset(train_dataset, val_indices)
    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=64)

    # Loss function
    criterion = nn.MSELoss()

    optim = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.01)
    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.1)

    num_epochs = 100
    train_losses = []
    val_losses = []
    for epoch in range(num_epochs):
        running_loss = 0.0
        model.train()
        for i, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = criterion(outputs, labels)
            optim.zero_grad()
            loss.backward()
            optim.step()

            running_loss += loss.item()

            if (i + 1) % 25 == 0:  # print every 25 batch
                print(f"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Current Loss: {loss.item():.4f}")

        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)

        scheduler.step()
        if (epoch + 1) % 5 == 0:  # Validation loss is calculated every 5 epochs
            model.eval()
            with torch.no_grad():
                val_loss = 0.0
                for images, labels in val_loader:
                    images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
                    outputs = model(images)
                    loss = criterion(outputs, labels.float())
                    val_loss += loss.item()
                val_loss /= len(val_loader)
                val_losses.append(val_loss)

            print(f"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
        else:
            print(f"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}")

    print('Training finished')

    # Plotting training and validation loss curves
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(range(1, num_epochs + 1, 5), val_losses, label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

    # Save the trained model
    model.eval()
    model_path = 'clocks_cnn.pth'
    torch.save(model.state_dict(), model_path)


# Starting Train
train()





def predict(img_path, model_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CartoonClockCNN().to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    image = Image.open(img_path)
    image_tensor = preprocess_image(image)
    image_tensor = image_tensor.unsqueeze(0).to(device)
    output = model(image_tensor)
    output = output.cpu().detach().numpy()[0]

    # Decoding
    predicted_hour = int((math.atan2(output[1], output[0]) + 2 * math.pi) % (2 * math.pi) / (2 * math.pi) * 12)
    predicted_minute = int((math.atan2(output[3], output[2]) + 2 * math.pi) % (2 * math.pi) / (2 * math.pi) * 60)
    return predicted_hour, predicted_minute


# Starting Predict
model_path = 'clocks_cnn.pth'
img_path = "datasets/clocks_dataset/train/0006.png"
predicted_hour, predicted_minute = predict(img_path, model_path)

label_path = img_path.replace('.png', '.txt')
with open(label_path, 'r') as f:
    label = f.read().strip().split(':')
    hour, minute = float(label[0]), float(label[1])
image = Image.open(img_path)

# Create an ImageDraw object to draw text on the image.
draw = ImageDraw.Draw(image)

# Defining fonts and font sizes
font = ImageFont.truetype("arial.ttf", 24)

# Plotting predicted values and true labels on images
draw.text((10, 10), f"Predicted: {predicted_hour:02d}:{predicted_minute:02d}", font=font, fill=(255, 0, 0))
draw.text((10, 40), f"Label: {int(hour):02d}:{int(minute):02d}", font=font, fill=(0, 255, 0))

# Show image
plt.figure(figsize=(6, 6))
plt.imshow(image)
plt.axis('off')
plt.show()


# This Model Weights shares on Google Drive
file_id = "1knK7DiiF6JiHUIalX_JaMxfecvJ1tUl-"














from google.colab import drive
drive.mount('/content/drive')


import zipfile
zip_path = '/content/drive/My Drive/datasets/clocks_dataset.zip'
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall('/content')


import math
import os
import cv2
import numpy as np
import torch
from PIL import Image
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from torch.ao.quantization import quantize_dynamic
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import random


# dataloader
class ClockDataset(Dataset):
    def __init__(self, data_dir, augment=True):
        self.data_dir = data_dir
        self.images = [filename for filename in os.listdir(data_dir) if filename.endswith('.png')]
        self.augment = augment

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.data_dir, self.images[idx])
        image = Image.open(img_path)
        normalized_tensor = preprocess_image(image, augment=self.augment)
        label_path = img_path.replace('.png', '.txt')
        with open(label_path, 'r') as f:
            label = f.read().strip().split(':')
            hour, minute = float(label[0]), float(label[1])
            # Cycle Encoding
            encoded_hour = [math.sin(2 * math.pi * hour / 12), math.cos(2 * math.pi * hour / 12)]
            encoded_minute = [math.sin(2 * math.pi * minute / 60), math.cos(2 * math.pi * minute / 60)]

        return normalized_tensor, torch.tensor(encoded_hour + encoded_minute, dtype=torch.float32)


# channel attention
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)

        # MLP
        self.fc1 = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)  # kernel_size=1
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)

        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))
        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))
        # 结果相加
        out = avg_out + max_out
        return self.sigmoid(out)


# spatial attention
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()
        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'
        padding = 3 if kernel_size == 7 else 1

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)


class CBAM(nn.Module):
    def __init__(self, in_channels):
        super(CBAM, self).__init__()
        self.channel_att = ChannelAttention(in_channels)
        self.spatial_att = SpatialAttention()

    def forward(self, x):
        att = 1 + self.channel_att(x) * x
        att = att + self.spatial_att(att)
        return att


class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample
        self.cbam = CBAM(out_channels)

    def forward(self, x):
        residual = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out = self.cbam(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = F.relu(out)
        return out

class CartoonClockCNN(nn.Module):
    def __init__(self):
        super(CartoonClockCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)

        self.layer1 = self._make_layer(16, 32, 2)
        self.layer2 = self._make_layer(32, 64, 2)
        self.layer3 = self._make_layer(64, 128, 2)
        self.layer4 = self._make_layer(128, 256, 2)
        # self.layer5 = self._make_layer(256, 512, 2)

        self.fc1 = nn.Linear(256 * 4 * 4, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 4)
        self.dropout = nn.Dropout(0.5)

    def _make_layer(self, in_channels, out_channels, blocks, stride=1):
        downsample = None
        if stride != 1 or in_channels != out_channels:
            downsample = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
        layers = []
        layers.append(ResidualBlock(in_channels, out_channels, stride, downsample))
        for _ in range(1, blocks):
            layers.append(ResidualBlock(out_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.layer1(x)
        x = F.max_pool2d(x, 2, 2)
        x = self.layer2(x)
        x = F.max_pool2d(x, 2, 2)
        x = self.layer3(x)
        x = F.max_pool2d(x, 2, 2)
        x = self.layer4(x)
        x = F.max_pool2d(x, 2, 2)
        # x = self.layer5(x)
        # x = F.max_pool2d(x, 2, 2)

        x = x.view(x.size(0), -1)
        x = F.relu(self.dropout(self.fc1(x)))
        x = F.relu(self.fc2(x))
        x = torch.tanh(self.fc3(x))
        return x


def preprocess_image(image, augment=False, augment_prob=0.8):
    def add_noise(tensor):
        noise = torch.randn(tensor.size()) * 0.01
        tensor = tensor + noise
        return tensor
    transform_list = [transforms.Resize((64, 64)),
                      transforms.ToTensor(),
                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]

    augment_transforms = [transforms.ColorJitter(),
                          transforms.RandomErasing(scale=(0.01, 0.01)),
                          transforms.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.7, 1.2))]

    # If data enhancement is performed, some enhanced transformations are randomly selected and added to the transformation list
    if augment and random.random() < augment_prob:
        selected_augment_transforms = random.sample(augment_transforms, k=random.randint(1, len(augment_transforms)))
        transform_list.extend(selected_augment_transforms)
        # Adding Noise with Lambda Transformations
        transform_list.append(transforms.Lambda(add_noise))

    composed_transforms = transforms.Compose(transform_list)
    augmented_tensor = composed_transforms(image)

    return augmented_tensor


def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # Creating a Network Instance
    model = CartoonClockCNN().to(device)
    train_dataset = ClockDataset('/content/train')
    # train_dataset = ClockDataset('datasets/sub_clock')

    # Splite Dataset
    train_data, val_data = train_test_split(list(range(len(train_dataset))), test_size=0.2)
    train_subset = torch.utils.data.Subset(train_dataset, train_data)
    val_subset = torch.utils.data.Subset(train_dataset, val_data)
    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=64)

    # Loss function
    criterion = nn.MSELoss()

    optim = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.01)
    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.1)

    num_epochs = 100
    train_losses = []
    all_losses = []
    val_losses = []
    for epoch in range(num_epochs):
        running_loss = 0.0
        model.train()
        for i, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = criterion(outputs, labels)
            optim.zero_grad()
            loss.backward()
            optim.step()

            all_losses.append(loss.item())
            running_loss += loss.item()

            if (i + 1) % 25 == 0:  # print every 25 batch
                print(
                    f"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Current Loss: {loss.item():.4f}")

        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)

        scheduler.step()
        if (epoch + 1) % 5 == 0:  # Validation loss is calculated every 5 epochs
            model.eval()
            with torch.no_grad():
                val_loss = 0.0
                for images, labels in val_loader:
                    images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
                    outputs = model(images)
                    loss = criterion(outputs, labels.float())
                    val_loss += loss.item()
                val_loss /= len(val_loader)
                val_losses.append(val_loss)

            print(f"Epoch [{epoch + 1}/{num_epochs}], Train Avg Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
        else:
            print(f"Epoch [{epoch + 1}/{num_epochs}], Train Avg Loss: {train_loss:.4f}")

    print('Training finished')

    # Save the trained model
    model.eval()
    model_path = 'cartoon_clocks_cnn.pth'
    torch.save(model.state_dict(), model_path)
    print('Model Saved')

    # Plotting training and validation loss curves
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(range(1, num_epochs + 1, 5), val_losses, label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()


def predict(img_path, model_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CartoonClockCNN().to(device)
    model.eval()
    model.load_state_dict(torch.load(model_path))
    model.eval()

    image = Image.open(img_path)
    image_tensor = preprocess_image(image)
    image_tensor = image_tensor.unsqueeze(0).to(device)
    output = model(image_tensor)
    output = output.cpu().detach().numpy()[0]

    # Decoding
    predicted_hour = int((math.atan2(output[1], output[0]) + 2 * math.pi) % (2 * math.pi) / (2 * math.pi) * 12)
    predicted_minute = int((math.atan2(output[3], output[2]) + 2 * math.pi) % (2 * math.pi) / (2 * math.pi) * 60)
    print(predicted_hour, predicted_minute)
    return predicted_hour, predicted_minute

if __name__ == '__main__':
    train()

    # model_path = 'cartoon_clocks_cnn.pth'
    # img_path = "/content/train/0046.png"
    # predict(img_path, model_path)



# Predict

from PIL import Image, ImageDraw, ImageFont
# Starting Predict
model_path = '/content/cartoon_clocks_cnn.pth'
img_path = "/content/train/0964.png"
predicted_hour, predicted_minute = predict(img_path, model_path)

label_path = img_path.replace('.png', '.txt')
with open(label_path, 'r') as f:
    label = f.read().strip().split(':')
    hour, minute = float(label[0]), float(label[1])
image = Image.open(img_path)

# Create an ImageDraw object to draw text on the image.
draw = ImageDraw.Draw(image)

# Defining fonts and font sizes
# font = ImageFont.truetype('arial.ttf', size=30)
font = ImageFont.load_default()

# Plotting predicted values and true labels on images
draw.text((10, 10), f"Predicted: {predicted_hour:02d}:{predicted_minute:02d}", font=font, fill=(255, 0, 0))
draw.text((10, 40), f"Label: {int(hour):02d}:{int(minute):02d}", font=font, fill=(0, 255, 0))

# Show image
plt.figure(figsize=(6, 6))
plt.imshow(image)
plt.axis('off')
plt.show()


import shutil
import os

local_file_path = 'cartoon_clocks_cnn.pth'
# Google Drive path
drive_path = '/content/drive/My Drive/PADL_share'
file_path = os.path.join(drive_path, 'cartoon_clocks_cnn.pth')
# Copy to Google Drive
shutil.copy(local_file_path, file_path)
print(f'File {local_file_path} has been uploaded to {file_path}')


# import gdown
get_ipython().getoutput("pip install gdown")

from google.colab import drive
drive.mount('/content/drive')

import gdown

# Google Drive shared FILE_ID
file_id = '1b9Ac9EPyQZTlQCz2B79DcJgwG4mW-eXA'
download_url = f'https://drive.google.com/uc?id={file_id}'
output = 'cartoon_clocks_cnn.pth'

# Download file
gdown.download(download_url, output, quiet=False)
print(f'File downloaded as: {output}')






import os
import torch
import torch.nn as nn
from PIL import Image
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from torchvision.utils import make_grid


# Define some parameters
batch_size = 100
nz = 100  # Size of z latent vector (i.e. size of generator input)
ngf = 64  # Size of feature maps in generator
ndf = 64  # Size of feature maps in discriminator
num_epochs = 50  # Number of training epochs
lrG = 1e-4
lrD = 4e-4
beta1 = 0.5  # Beta1 hyperparam for Adam optimizers
nc = 3  # 输出图像通道数


class ClockDataset(Dataset):
    def __init__(self, data_dir, augment=True):
        self.data_dir = data_dir
        self.images = [filename for filename in os.listdir(data_dir) if filename.endswith('.png')]
        self.augment = augment

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.data_dir, self.images[idx])
        image = Image.open(img_path).convert('RGB')
        composed_transforms = transforms.Compose([transforms.Resize((64, 64)),
                                                  transforms.RandomHorizontalFlip(),
                                                  transforms.RandomVerticalFlip(),
                                                  transforms.ToTensor(),
                                                  transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                                                       std=[0.229, 0.224, 0.225])
                                                  ])
        normalized_tensor = composed_transforms(image)

        label_path = img_path.replace('.png', '.txt')
        with open(label_path, 'r') as f:
            label = f.read().strip().split(':')
            hour, minute = label[0], label[1]
            normalized_hour = float(int(hour) / 11 * 2 - 1)
            normalized_minute = float(int(minute) / 59 * 2 - 1)
            normalized_label = torch.tensor([normalized_hour, normalized_minute], dtype=torch.float32)
        return normalized_tensor, normalized_label


# Set up the dataset and dataloader
dataset = ClockDataset('datasets/clocks_dataset/train')
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def spectral_norm(module, mode=True):
    if mode:
        return nn.utils.spectral_norm(module)
    return module


class Generator(nn.Module):
    def __init__(self, nz, ngf, nc):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz + 2, ngf * 8, 4, 1, 0, bias=False),
            nn.ReLU(True),
            nn.BatchNorm2d(ngf * 8),

            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.ReLU(True),
            nn.BatchNorm2d(ngf * 4),

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.ReLU(True),
            nn.BatchNorm2d(ngf * 2),

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),

            spectral_norm(nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False)),
            nn.Tanh()
        )

    def forward(self, input, labels):
        # Expand labels to [batch_size, 2, 1, 1]
        labels = labels.unsqueeze(2).unsqueeze(3)
        labels = labels.expand(-1, -1, 1, 1)
        # Combine noise vector and labels
        combined_input = torch.cat([input, labels], dim=1)
        return self.main(combined_input)


class Discriminator(nn.Module):
    def __init__(self, ndf, nc):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            # state size. 1 x 32 x 32
            nn.Conv2d(nc + 2, ndf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 16 x 16
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 8 x 8
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 4 x 4
            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input, labels):
        # Expand labels to [batch_size, 2, height, width]
        labels = labels.unsqueeze(2).unsqueeze(3)
        labels = labels.expand(-1, -1, input.shape[2], input.shape[3])
        # Combine images and labels
        combined_input = torch.cat([input, labels], 1)
        return self.main(combined_input)







def train():
    netG = Generator(nz, ngf, nc)
    netG = netG.to(device)

    netD = Discriminator(ndf, nc)
    netD = netD.to(device)

    # Initialize BCELoss function
    criterion = nn.BCELoss()

    # Establish convention for real and fake labels during training
    real_label = 1.
    fake_label = 0.

    # Setup Adam optimizers for both G and D
    optimizerD = optim.Adam(netD.parameters(), lr=lrD, betas=(beta1, 0.999))
    optimizerG = optim.Adam(netG.parameters(), lr=lrG, betas=(beta1, 0.999))

    # Learning rate schedulers
    schedulerD = optim.lr_scheduler.StepLR(optimizerD, step_size=30, gamma=0.1)
    schedulerG = optim.lr_scheduler.StepLR(optimizerG, step_size=30, gamma=0.1)

    # Lists to keep track of progress
    G_losses = []
    D_losses = []

    # Training Loop
    print("Starting Training Loop...")
    # For each epoch
    for epoch in range(num_epochs):
        # For each batch in the dataloader
        for i, (images, labels) in enumerate(dataloader, 0):
            ############################
            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
            ###########################
            ## Train with all-real batch
            netD.zero_grad()
            # Format batch
            real_images = images.to(device)
            labels = labels.to(device)
            batch_size = real_images.size(0)
            # To prevent the discriminator from being too powerful, add a small amount of noise to the input data
            real_images += 0.01 * torch.randn_like(real_images)
            # Forward pass real batch through D
            output = netD(real_images, labels).view(-1)

            real_label_tensor = torch.full_like(output, real_label, dtype=torch.float, device=device)
            # Calculate loss on all-real batch
            errD_real = criterion(output, real_label_tensor)
            # Calculate gradients for D in backward pass
            errD_real.backward()
            D_x = output.mean().item()

            ## Train with all-fake batch
            z = torch.randn(batch_size, nz, 1, 1, device=device)
            # [-1, 1]
            z = torch.clamp(z, -1, 1)
            # Generate fake image batch with G
            fake_images = netG(z, labels)
            # Classify all fake batch with D
            output = netD(fake_images.detach(), labels).view(-1)
            fake_label_tensor = torch.full_like(output, fake_label, dtype=torch.float, device=device)
            # Calculate D's loss on the all-fake batch
            errD_fake = criterion(output, fake_label_tensor)
            # Calculate the gradients for this batch, accumulated (summed) with previous gradients
            errD_fake.backward()
            D_G_z1 = output.mean().item()
            # Compute error of D as sum over the fake and the real batches
            errD = errD_real + errD_fake
            # Update D
            optimizerD.step()

            # for p in netD.parameters():
            #     p.data.clamp_(-opt.clip_value, opt.clip_value)

            ############################
            # (2) Update G network: maximize log(D(G(z)))
            ###########################
            # for _ in range(2):  # Update G more frequently
            if i % 5 == 0:
                netG.zero_grad()
                # Since we just updated D, perform another forward pass of all-fake batch through D
                output = netD(fake_images, labels).view(-1)
                # Calculate G's loss based on this output
                # fake labels are real for generator cost
                # real_label_tensor = torch.full((output.size(0),), 1, dtype=torch.float, device=device)  # 生成器目标是让判别器认为生成的图像是真实的
                real_label_tensor = torch.empty((output.size(0),), dtype=torch.float, device=device).uniform_(0.9, 1.0)
                errG = criterion(output, real_label_tensor)
                # Calculate gradients for G
                errG.backward(retain_graph=True)
                D_G_z2 = output.mean().item()
                # Update G
                optimizerG.step()

            # Save Losses for plotting later
            G_losses.append(errG.item())
            D_losses.append(errD.item())

            # Output training stats
            if i % 50 == 0:
                print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                      % (epoch + 1, num_epochs, i, len(dataloader),
                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Update learning rates
        schedulerD.step()
        schedulerG.step()
    print("Train Finished.")
    print("Strat Save Models...")
    # Save Model
    torch.save(netG.state_dict(), 'generator.pth')
    torch.save(netD.state_dict(), 'discriminator.pth')
    print("Models Saved")

    # Plot the losses
    plt.figure(figsize=(10, 5))
    plt.title("Generator and Discriminator Loss During Training")
    plt.plot(G_losses, label="G")
    plt.plot(D_losses, label="D")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()


train()





def generate_images_for_times(netG, times, num_samples=4):
    images = []
    for time in times:
        hour, minute = time
        normalized_hour = float(int(hour) / 11 * 2 - 1)
        normalized_minute = float(int(minute) / 59 * 2 - 1)
        labels = torch.tensor([normalized_hour, normalized_minute], dtype=torch.float32, device=device).view(1, 2)

    for _ in range(num_samples):
        noise = torch.randn(1, nz, 1, 1, device=device)
        noise = torch.clamp(noise, -1, 1)
        with torch.no_grad():
            fake_image = netG(noise, labels).cpu()
        images.append(fake_image.squeeze())

    grid = make_grid(images, nrow=num_samples, normalize=True)
    return grid


def generate_random_samples(netG, num_samples=8):
    images = []
    for _ in range(num_samples):
        noise = torch.randn(1, nz, 1, 1, device=device)
        # Restrict the noise vector to the range [-1, 1
        noise = torch.clamp(noise, -1, 1)

        random_hour = torch.randint(0, 12, (1,)).item() / 11.0 * 2 - 1  
        random_minute = torch.randint(0, 60, (1,)).item() / 59.0 * 2 - 1  
        labels = torch.tensor([random_hour, random_minute], dtype=torch.float32, device=device).view(1, 2)  
        with torch.no_grad():
            fake_image = netG(noise, labels).cpu()
        images.append(fake_image.squeeze())

    grid = make_grid(images, nrow=4, normalize=True)
    return grid


def interpolate_images(netG, start_latent, end_latent, num_steps, label):
    interpolated_images = []
    for alpha in torch.linspace(0, 1, num_steps):
        interpolated_latent = (1 - alpha) * start_latent + alpha * end_latent
        with torch.no_grad():
            fake_image = netG(interpolated_latent, label).cpu()
        interpolated_images.append(fake_image.squeeze())
    return interpolated_images


def generate_interpolated_images_for_time(netG, time, num_interpolations=5):
    hour, minute = time
    normalized_hour = float(int(hour) / 11 * 2 - 1)
    normalized_minute = float(int(minute) / 59 * 2 - 1)
    labels = torch.tensor([normalized_hour, normalized_minute], dtype=torch.float32, device=device).view(1, 2)

    # Generate two random noise vectors
    start_latent = torch.randn(1, nz, 1, 1, device=device)
    # Restrict the noise vector to the range [-1, 1
    start_latent = torch.clamp(start_latent, -1, 1)
    end_latent = torch.randn(1, nz, 1, 1, device=device)
    end_latent = torch.clamp(end_latent, -1, 1)

    # Perform interpolation and generate images
    images = interpolate_images(netG, start_latent, end_latent, num_interpolations + 2, labels)
    grid = make_grid(images, nrow=num_interpolations + 2, normalize=True)
    return grid


def predict():
    # Define some parameters

    # train()
    netG = Generator(nz, ngf, nc)
    netG = netG.to(device)
    netG.load_state_dict(torch.load('generator.pth', map_location=torch.device(device)))
    netG.eval()

    # Generate 4×4 grid images
    times = [(10, 30), (14, 45), (18, 15), (22, 0)]  # Four randomly selected times
    grid = generate_images_for_times(netG, times)

    plt.figure(figsize=(8, 8))
    plt.imshow(grid.permute(1, 2, 0).numpy())
    plt.axis('off')
    plt.show()

    # Generate images of 8 random samples
    random_grid = generate_random_samples(netG)

    plt.figure(figsize=(8, 8))
    plt.imshow(random_grid.permute(1, 2, 0).numpy())
    plt.axis('off')
    plt.show()

    # interpolation
    times = [(10, 30), (11, 45), (6, 15), (3, 0)]  
    fig, axes = plt.subplots(len(times), 1, figsize=(15, 15))

    for i, time in enumerate(times):
        grid = generate_interpolated_images_for_time(netG, time)
        axes[i].imshow(grid.permute(1, 2, 0).numpy())
        axes[i].axis('off')
        axes[i].set_title(f"Interpolation for time {time[0]:02d}:{time[1]:02d}")

    plt.tight_layout()
    plt.show()


predict()



